# Configuration & CLI
hydra-core>=1.2
omegaconf>=2.3

# Deep Learning & adapters - LLM focused
torch>=2.1.0,<2.4.0  # Updated to support register_fake
torchvision>=0.16.0,<0.20.0  # Compatible with PyTorch 2.1+
transformers>=4.30,<4.36
peft>=0.5,<0.7           # For LoRA adapters
accelerate>=0.20,<0.25    # For QLoRA + distributed training
bitsandbytes>=0.39,<0.42  # 8-bit optimizers (used in QLoRA)
numpy<2.0.0
pytest>=7.0

# Training framework - Updated for compatibility
pytorch-lightning>=2.1.0,<2.4.0  # Updated for PyTorch 2.1+ compatibility
torchmetrics>=1.2.0,<1.5.0  # Updated for compatibility

# Experiment tracking & logging
mlflow>=2.3
codecarbon>=2.0     # Green AI tracking

# Data processing & metrics
datasets>=2.11,<2.15
scikit-learn>=1.2
pandas>=2.0

# Dashboard & analysis 
streamlit>=1.20
plotly>=5.13        # For interactive charts

# Utilities & formatting
pyyaml>=6.0
tqdm>=4.65
loguru>=0.7

scipy>=1.10.0

# Optional for better performance (commented out to avoid compatibility issues)
# flash-attn>=2.0.0  # If available for your GPU - can cause compatibility issues
# xformers>=0.0.20   # Memory efficient attention - can cause compatibility issues

# Additional dependencies for stability
packaging>=21.0
typing-extensions>=4.0.0
filelock>=3.0.0
huggingface-hub>=0.16.0,<0.18.0
tokenizers>=0.13.0,<0.14.0
safetensors>=0.3.0,<0.4.0
